diff --git a/hudi-spark-datasource/hudi-spark-common/src/main/scala/org/apache/spark/sql/hudi/HoodieOptionConfig.scala b/hudi-spark-datasource/hudi-spark-common/src/main/scala/org/apache/spark/sql/hudi/HoodieOptionConfig.scala
index 89472466a2db7..27a1639c710ac 100644
--- a/hudi-spark-datasource/hudi-spark-common/src/main/scala/org/apache/spark/sql/hudi/HoodieOptionConfig.scala
+++ b/hudi-spark-datasource/hudi-spark-common/src/main/scala/org/apache/spark/sql/hudi/HoodieOptionConfig.scala
@@ -61,7 +61,7 @@ object HoodieOptionConfig {
   val SQL_KEY_PRECOMBINE_FIELD: HoodieSQLOption[String] = buildConf()
     .withSqlKey("preCombineField")
     .withHoodieKey(DataSourceWriteOptions.PRECOMBINE_FIELD.key)
-    .withTableConfigKey(HoodieTableConfig.PRECOMBINE_FIELDS.key)
+    .withTableConfigKey(HoodieTableConfig.ORDERING_FIELDS.key)
     .build()
 
   val SQL_PAYLOAD_CLASS: HoodieSQLOption[String] = buildConf()
@@ -181,11 +181,6 @@ object HoodieOptionConfig {
       DataSourceWriteOptions.TABLE_TYPE.defaultValue)
   }
 
-  def getPreCombineField(options: Map[String, String]): Option[String] = {
-    val params = mapSqlOptionsToDataSourceWriteConfigs(options)
-    params.get(DataSourceWriteOptions.PRECOMBINE_FIELD.key).filter(_.nonEmpty)
-  }
-
   def deleteHoodieOptions(options: Map[String, String]): Map[String, String] = {
     options.filterNot(_._1.startsWith("hoodie.")).filterNot(kv => sqlOptionKeyToWriteConfigKey.contains(kv._1))
   }
