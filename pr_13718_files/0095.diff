diff --git a/hudi-spark-datasource/hudi-spark/src/test/resources/upgrade-downgrade-fixtures/scala-templates/generate-fixture.scala b/hudi-spark-datasource/hudi-spark/src/test/resources/upgrade-downgrade-fixtures/scala-templates/generate-fixture.scala
index fbefed9e05dfc..46f4eb43ced42 100644
--- a/hudi-spark-datasource/hudi-spark/src/test/resources/upgrade-downgrade-fixtures/scala-templates/generate-fixture.scala
+++ b/hudi-spark-datasource/hudi-spark/src/test/resources/upgrade-downgrade-fixtures/scala-templates/generate-fixture.scala
@@ -16,6 +16,7 @@
  */
 
 import org.apache.spark.sql.SaveMode
+import org.apache.hudi.common.table.HoodieTableConfig
 import org.apache.hudi.DataSourceWriteOptions._
 import spark.implicits._
 
@@ -35,7 +36,7 @@ val df = testData.toDF("id", "name", "ts", "partition")
 
 // Write initial batch (creates base files)
 df.write.format("hudi").
-  option(PRECOMBINE_FIELD.key, "ts").
+  option(HoodieTableConfig.ORDERING_FIELDS.key, "ts").
   option(RECORDKEY_FIELD.key, "id").
   option(PARTITIONPATH_FIELD.key, "partition").
   option("hoodie.table.name", tableName).
@@ -61,7 +62,7 @@ val updateData = Seq(
 val updateDf = updateData.toDF("id", "name", "ts", "partition")
 
 updateDf.write.format("hudi").
-  option(PRECOMBINE_FIELD.key, "ts").
+  option(HoodieTableConfig.ORDERING_FIELDS.key, "ts").
   option(RECORDKEY_FIELD.key, "id").
   option(PARTITIONPATH_FIELD.key, "partition").
   option("hoodie.table.name", tableName).
@@ -86,7 +87,7 @@ val insertData = Seq(
 val insertDf = insertData.toDF("id", "name", "ts", "partition")
 
 insertDf.write.format("hudi").
-  option(PRECOMBINE_FIELD.key, "ts").
+  option(HoodieTableConfig.ORDERING_FIELDS.key, "ts").
   option(RECORDKEY_FIELD.key, "id").
   option(PARTITIONPATH_FIELD.key, "partition").
   option("hoodie.table.name", tableName).
