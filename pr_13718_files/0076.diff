diff --git a/hudi-spark-datasource/hudi-spark/src/main/scala/org/apache/spark/sql/hudi/command/MergeIntoHoodieTableCommand.scala b/hudi-spark-datasource/hudi-spark/src/main/scala/org/apache/spark/sql/hudi/command/MergeIntoHoodieTableCommand.scala
index 56507994fa69d..398e3f766c1ee 100644
--- a/hudi-spark-datasource/hudi-spark/src/main/scala/org/apache/spark/sql/hudi/command/MergeIntoHoodieTableCommand.scala
+++ b/hudi-spark-datasource/hudi-spark/src/main/scala/org/apache/spark/sql/hudi/command/MergeIntoHoodieTableCommand.scala
@@ -268,7 +268,7 @@ case class MergeIntoHoodieTableCommand(mergeInto: MergeIntoTable,
       sparkSession.sessionState.conf.resolver,
       mergeInto.targetTable,
       mergeInto.sourceTable,
-      hoodieCatalogTable.preCombineKeys.asScala.toSeq,
+      hoodieCatalogTable.orderingFields.asScala.toSeq,
       "precombine field",
       updatingActions.flatMap(_.assignments))
 
@@ -761,7 +761,7 @@ case class MergeIntoHoodieTableCommand(mergeInto: MergeIntoTable,
     // NOTE: Here we fallback to "" to make sure that null value is not overridden with
     // default value ("ts")
     // TODO(HUDI-3456) clean up
-    val preCombineFieldsAsString = String.join(",", hoodieCatalogTable.preCombineKeys)
+    val orderingFieldsAsString = String.join(",", hoodieCatalogTable.orderingFields)
     val hiveSyncConfig = buildHiveSyncConfig(sparkSession, hoodieCatalogTable, tableConfig)
     // for pkless tables, we need to enable optimized merge
     val isPrimaryKeylessTable = !hasPrimaryKey()
@@ -776,7 +776,7 @@ case class MergeIntoHoodieTableCommand(mergeInto: MergeIntoTable,
         tableConfig.getRecordMergeMode,
         tableConfig.getPayloadClass,
         tableConfig.getRecordMergeStrategyId,
-        tableConfig.getPreCombineFieldsStr.orElse(null),
+        tableConfig.getOrderingFieldsStr.orElse(null),
         tableConfig.getTableVersion)
       inferredMergeConfigs.getLeft.name()
     } else {
@@ -785,7 +785,7 @@ case class MergeIntoHoodieTableCommand(mergeInto: MergeIntoTable,
     val overridingOpts = Map(
       "path" -> path,
       RECORDKEY_FIELD.key -> tableConfig.getRawRecordKeyFieldProp,
-      PRECOMBINE_FIELD.key -> preCombineFieldsAsString,
+      HoodieTableConfig.ORDERING_FIELDS.key -> orderingFieldsAsString,
       TBL_NAME.key -> hoodieCatalogTable.tableName,
       PARTITIONPATH_FIELD.key -> getPartitionPathFieldWriteConfig(
         tableConfig.getKeyGeneratorClassName, tableConfig.getPartitionFieldProp, hoodieCatalogTable),
@@ -819,7 +819,7 @@ case class MergeIntoHoodieTableCommand(mergeInto: MergeIntoTable,
       HoodieSparkSqlWriter.SQL_MERGE_INTO_WRITES.key -> "true",
       // Only primary keyless table requires prepped keys and upsert
       HoodieWriteConfig.SPARK_SQL_MERGE_INTO_PREPPED_KEY -> isPrimaryKeylessTable.toString,
-      HoodieWriteConfig.COMBINE_BEFORE_UPSERT.key() -> (!StringUtils.isNullOrEmpty(preCombineFieldsAsString)).toString
+      HoodieWriteConfig.COMBINE_BEFORE_UPSERT.key() -> (!StringUtils.isNullOrEmpty(orderingFieldsAsString)).toString
     )
 
     combineOptions(hoodieCatalogTable, tableConfig, sparkSession.sqlContext.conf,
@@ -851,7 +851,7 @@ case class MergeIntoHoodieTableCommand(mergeInto: MergeIntoTable,
         validateTargetTableAttrExistsInAssignments(
           sparkSession.sessionState.conf.resolver,
           mergeInto.targetTable,
-          hoodieCatalogTable.preCombineKeys.asScala.toSeq,
+          hoodieCatalogTable.orderingFields.asScala.toSeq,
           "precombine field",
           action.assignments)
       )
@@ -921,7 +921,7 @@ case class MergeIntoHoodieTableCommand(mergeInto: MergeIntoTable,
             sparkSession.sessionState.conf.resolver,
             mergeInto.targetTable,
             mergeInto.sourceTable,
-            hoodieCatalogTable.preCombineKeys.asScala.toSeq,
+            hoodieCatalogTable.orderingFields.asScala.toSeq,
             "precombine field",
             assignments)
           associations.foreach(association => validateDataTypes(association._1, association._2, "Precombine field"))
@@ -934,7 +934,7 @@ case class MergeIntoHoodieTableCommand(mergeInto: MergeIntoTable,
   }
 
   private def checkUpdatingActions(updateActions: Seq[UpdateAction], props: Map[String, String]): Unit = {
-    if (hoodieCatalogTable.preCombineKeys.isEmpty && updateActions.nonEmpty) {
+    if (hoodieCatalogTable.orderingFields.isEmpty && updateActions.nonEmpty) {
       logWarning(s"Updates without precombine can have nondeterministic behavior")
     }
     updateActions.foreach(update =>
