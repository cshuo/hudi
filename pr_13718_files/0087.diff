diff --git a/hudi-spark-datasource/hudi-spark/src/test/java/org/apache/hudi/functional/TestBufferedRecordMerger.java b/hudi-spark-datasource/hudi-spark/src/test/java/org/apache/hudi/functional/TestBufferedRecordMerger.java
index ccc507aba3447..0b3047bc3d858 100644
--- a/hudi-spark-datasource/hudi-spark/src/test/java/org/apache/hudi/functional/TestBufferedRecordMerger.java
+++ b/hudi-spark-datasource/hudi-spark/src/test/java/org/apache/hudi/functional/TestBufferedRecordMerger.java
@@ -76,7 +76,7 @@
 import static org.apache.hudi.common.config.RecordMergeMode.COMMIT_TIME_ORDERING;
 import static org.apache.hudi.common.config.RecordMergeMode.EVENT_TIME_ORDERING;
 import static org.apache.hudi.common.table.HoodieTableConfig.PARTIAL_UPDATE_CUSTOM_MARKER;
-import static org.apache.hudi.common.table.HoodieTableConfig.PRECOMBINE_FIELDS;
+import static org.apache.hudi.common.table.HoodieTableConfig.ORDERING_FIELDS;
 import static org.junit.jupiter.api.Assertions.assertEquals;
 import static org.junit.jupiter.api.Assertions.assertFalse;
 import static org.junit.jupiter.api.Assertions.assertNotNull;
@@ -113,7 +113,7 @@ void setUp() throws IOException {
     when(tableConfig.getRecordKeyFields()).thenReturn(Option.of(new String[]{"id"}));
     // Create reader context.
     props = new TypedProperties();
-    props.put(PRECOMBINE_FIELDS.key(), "precombine");
+    props.put(ORDERING_FIELDS.key(), "precombine");
     readerContext = new DummyInternalRowReaderContext(
         storageConfig, tableConfig, Option.empty(), Option.empty(), new DummyRecordContext(tableConfig));
   }
