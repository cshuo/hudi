diff --git a/hudi-spark-datasource/hudi-spark/src/test/java/org/apache/hudi/TestDecimalTypeDataWorkflow.scala b/hudi-spark-datasource/hudi-spark/src/test/java/org/apache/hudi/TestDecimalTypeDataWorkflow.scala
index c4014bc5719ac..54815dd394a93 100644
--- a/hudi-spark-datasource/hudi-spark/src/test/java/org/apache/hudi/TestDecimalTypeDataWorkflow.scala
+++ b/hudi-spark-datasource/hudi-spark/src/test/java/org/apache/hudi/TestDecimalTypeDataWorkflow.scala
@@ -21,6 +21,7 @@ package org.apache.hudi
 
 import org.apache.hudi.DataSourceWriteOptions._
 import org.apache.hudi.common.config.{HoodieReaderConfig, HoodieStorageConfig}
+import org.apache.hudi.common.table.HoodieTableConfig
 import org.apache.hudi.config.HoodieWriteConfig
 import org.apache.hudi.testutils.SparkClientFunctionalTestHarness
 import org.apache.spark.sql.types.{Decimal, DecimalType, IntegerType, StructField, StructType}
@@ -66,7 +67,7 @@ class TestDecimalTypeDataWorkflow extends SparkClientFunctionalTestHarness{
       .toDF("id", "decimal_col").sort("id")
     insertDf.write.format("hudi")
       .option(RECORDKEY_FIELD.key(), "id")
-      .option(PRECOMBINE_FIELD.key(), "decimal_col")
+      .option(HoodieTableConfig.ORDERING_FIELDS.key(), "decimal_col")
       .option(TABLE_TYPE.key, "MERGE_ON_READ")
       .option(TABLE_NAME.key, "test_table")
       .options(opts)
